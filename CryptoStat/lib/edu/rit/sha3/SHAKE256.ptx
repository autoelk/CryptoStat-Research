//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-26907403
// Cuda compilation tools, release 10.1, V10.1.243
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_30
.address_size 64

	// .globl	evaluateFunction
.const .align 8 .b8 K[192] = {1, 0, 0, 0, 0, 0, 0, 0, 130, 128, 0, 0, 0, 0, 0, 0, 138, 128, 0, 0, 0, 0, 0, 128, 0, 128, 0, 128, 0, 0, 0, 128, 139, 128, 0, 0, 0, 0, 0, 0, 1, 0, 0, 128, 0, 0, 0, 0, 129, 128, 0, 128, 0, 0, 0, 128, 9, 128, 0, 0, 0, 0, 0, 128, 138, 0, 0, 0, 0, 0, 0, 0, 136, 0, 0, 0, 0, 0, 0, 0, 9, 128, 0, 128, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 0, 139, 128, 0, 128, 0, 0, 0, 0, 139, 0, 0, 0, 0, 0, 0, 128, 137, 128, 0, 0, 0, 0, 0, 128, 3, 128, 0, 0, 0, 0, 0, 128, 2, 128, 0, 0, 0, 0, 0, 128, 128, 0, 0, 0, 0, 0, 0, 128, 10, 128, 0, 0, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 128, 129, 128, 0, 128, 0, 0, 0, 128, 128, 128, 0, 0, 0, 0, 0, 128, 1, 0, 0, 128, 0, 0, 0, 0, 8, 128, 0, 128, 0, 0, 0, 128};

.visible .entry evaluateFunction(
	.param .u32 evaluateFunction_param_0,
	.param .u32 evaluateFunction_param_1,
	.param .u64 evaluateFunction_param_2,
	.param .u32 evaluateFunction_param_3,
	.param .u32 evaluateFunction_param_4,
	.param .u64 evaluateFunction_param_5,
	.param .u32 evaluateFunction_param_6,
	.param .u32 evaluateFunction_param_7,
	.param .u64 evaluateFunction_param_8
)
{
	.local .align 8 .b8 	__local_depot0[200];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<18>;
	.reg .b32 	%r<329>;
	.reg .b64 	%rd<751>;


	mov.u64 	%SPL, __local_depot0;
	ld.param.u32 	%r39, [evaluateFunction_param_0];
	ld.param.u32 	%r40, [evaluateFunction_param_1];
	ld.param.u64 	%rd120, [evaluateFunction_param_2];
	ld.param.u32 	%r41, [evaluateFunction_param_3];
	ld.param.u32 	%r42, [evaluateFunction_param_4];
	ld.param.u64 	%rd121, [evaluateFunction_param_5];
	ld.param.u32 	%r44, [evaluateFunction_param_7];
	mov.u32 	%r45, %ctaid.x;
	mov.u32 	%r46, %ntid.x;
	mov.u32 	%r47, %tid.x;
	mad.lo.s32 	%r316, %r45, %r46, %r47;
	mul.lo.s32 	%r48, %r41, %r39;
	setp.ge.s32	%p1, %r316, %r48;
	@%p1 bra 	BB0_28;

	shr.u32 	%r49, %r40, 31;
	add.s32 	%r50, %r40, %r49;
	shr.s32 	%r2, %r50, 1;
	mov.u32 	%r51, 1;
	max.s32 	%r3, %r2, %r51;
	shr.u32 	%r52, %r42, 31;
	add.s32 	%r53, %r42, %r52;
	shr.s32 	%r4, %r53, 1;
	max.s32 	%r5, %r4, %r51;

BB0_2:
	div.s32 	%r7, %r316, %r41;
	mul.lo.s32 	%r8, %r7, %r40;
	rem.s32 	%r9, %r316, %r41;
	mul.lo.s32 	%r10, %r9, %r42;
	add.u64 	%rd1, %SPL, 0;
	setp.lt.s32	%p2, %r40, 2;
	@%p2 bra 	BB0_12;

	and.b32  	%r57, %r3, 3;
	mov.u32 	%r317, 0;
	setp.eq.s32	%p3, %r57, 0;
	@%p3 bra 	BB0_9;

	setp.eq.s32	%p4, %r57, 1;
	@%p4 bra 	BB0_8;

	setp.eq.s32	%p5, %r57, 2;
	@%p5 bra 	BB0_7;

	add.s32 	%r59, %r40, %r8;
	add.s32 	%r60, %r59, -2;
	cvta.to.global.u64 	%rd124, %rd120;
	mul.wide.s32 	%rd125, %r60, 4;
	add.s64 	%rd126, %rd124, %rd125;
	ld.global.u32 	%rd127, [%rd126];
	ld.global.u32 	%rd128, [%rd126+4];
	shl.b64 	%rd129, %rd128, 32;
	or.b64  	%rd130, %rd129, %rd127;
	st.local.u64 	[%rd1], %rd130;
	mov.u32 	%r317, 1;

BB0_7:
	shl.b32 	%r61, %r317, 1;
	sub.s32 	%r62, %r40, %r61;
	add.s32 	%r63, %r62, %r8;
	add.s32 	%r64, %r63, -2;
	cvta.to.global.u64 	%rd131, %rd120;
	mul.wide.s32 	%rd132, %r64, 4;
	add.s64 	%rd133, %rd131, %rd132;
	ld.global.u32 	%rd134, [%rd133];
	ld.global.u32 	%rd135, [%rd133+4];
	shl.b64 	%rd136, %rd135, 32;
	or.b64  	%rd137, %rd136, %rd134;
	mul.wide.u32 	%rd140, %r317, 8;
	add.s64 	%rd141, %rd1, %rd140;
	st.local.u64 	[%rd141], %rd137;
	add.s32 	%r317, %r317, 1;

BB0_8:
	shl.b32 	%r65, %r317, 1;
	sub.s32 	%r66, %r40, %r65;
	add.s32 	%r67, %r66, %r8;
	add.s32 	%r68, %r67, -2;
	cvta.to.global.u64 	%rd142, %rd120;
	mul.wide.s32 	%rd143, %r68, 4;
	add.s64 	%rd144, %rd142, %rd143;
	ld.global.u32 	%rd145, [%rd144];
	ld.global.u32 	%rd146, [%rd144+4];
	shl.b64 	%rd147, %rd146, 32;
	or.b64  	%rd148, %rd147, %rd145;
	mul.wide.s32 	%rd151, %r317, 8;
	add.s64 	%rd152, %rd1, %rd151;
	st.local.u64 	[%rd152], %rd148;
	add.s32 	%r317, %r317, 1;

BB0_9:
	setp.lt.u32	%p6, %r3, 4;
	@%p6 bra 	BB0_12;

	mul.wide.s32 	%rd155, %r317, 8;
	add.s64 	%rd699, %rd1, %rd155;
	shl.b32 	%r69, %r317, 1;
	sub.s32 	%r320, %r40, %r69;
	cvta.to.global.u64 	%rd3, %rd120;

BB0_11:
	add.s32 	%r70, %r320, %r8;
	mul.wide.s32 	%rd156, %r70, 4;
	add.s64 	%rd157, %rd3, %rd156;
	ld.global.u32 	%rd158, [%rd157+-8];
	ld.global.u32 	%rd159, [%rd157+-4];
	shl.b64 	%rd160, %rd159, 32;
	or.b64  	%rd161, %rd160, %rd158;
	ld.global.u32 	%rd162, [%rd157+-16];
	ld.global.u32 	%rd163, [%rd157+-12];
	ld.global.u32 	%rd164, [%rd157+-24];
	ld.global.u32 	%rd165, [%rd157+-20];
	ld.global.u32 	%rd166, [%rd157+-32];
	ld.global.u32 	%rd167, [%rd157+-28];
	st.local.u64 	[%rd699], %rd161;
	shl.b64 	%rd168, %rd163, 32;
	or.b64  	%rd169, %rd168, %rd162;
	st.local.u64 	[%rd699+8], %rd169;
	shl.b64 	%rd170, %rd165, 32;
	or.b64  	%rd171, %rd170, %rd164;
	st.local.u64 	[%rd699+16], %rd171;
	shl.b64 	%rd172, %rd167, 32;
	or.b64  	%rd173, %rd172, %rd166;
	st.local.u64 	[%rd699+24], %rd173;
	add.s64 	%rd699, %rd699, 32;
	add.s32 	%r320, %r320, -8;
	add.s32 	%r317, %r317, 4;
	setp.lt.s32	%p7, %r317, %r2;
	@%p7 bra 	BB0_11;

BB0_12:
	setp.lt.s32	%p8, %r42, 2;
	@%p8 bra 	BB0_22;

	and.b32  	%r74, %r5, 3;
	mov.u32 	%r322, 0;
	setp.eq.s32	%p9, %r74, 0;
	@%p9 bra 	BB0_19;

	setp.eq.s32	%p10, %r74, 1;
	@%p10 bra 	BB0_18;

	setp.eq.s32	%p11, %r74, 2;
	@%p11 bra 	BB0_17;

	mov.u32 	%r322, 1;
	add.s32 	%r76, %r42, %r10;
	add.s32 	%r77, %r76, -2;
	cvta.to.global.u64 	%rd174, %rd121;
	mul.wide.s32 	%rd175, %r77, 4;
	add.s64 	%rd176, %rd174, %rd175;
	ld.global.u32 	%rd177, [%rd176];
	ld.global.u32 	%rd178, [%rd176+4];
	shl.b64 	%rd179, %rd178, 32;
	or.b64  	%rd180, %rd179, %rd177;
	st.local.u64 	[%rd1+32], %rd180;

BB0_17:
	shl.b32 	%r78, %r322, 1;
	sub.s32 	%r79, %r42, %r78;
	add.s32 	%r80, %r79, %r10;
	add.s32 	%r81, %r80, -2;
	cvta.to.global.u64 	%rd181, %rd121;
	mul.wide.s32 	%rd182, %r81, 4;
	add.s64 	%rd183, %rd181, %rd182;
	ld.global.u32 	%rd184, [%rd183];
	ld.global.u32 	%rd185, [%rd183+4];
	shl.b64 	%rd186, %rd185, 32;
	or.b64  	%rd187, %rd186, %rd184;
	add.s32 	%r82, %r322, 4;
	mul.wide.u32 	%rd190, %r82, 8;
	add.s64 	%rd191, %rd1, %rd190;
	st.local.u64 	[%rd191], %rd187;
	add.s32 	%r322, %r322, 1;

BB0_18:
	shl.b32 	%r83, %r322, 1;
	sub.s32 	%r84, %r42, %r83;
	add.s32 	%r85, %r84, %r10;
	add.s32 	%r86, %r85, -2;
	cvta.to.global.u64 	%rd192, %rd121;
	mul.wide.s32 	%rd193, %r86, 4;
	add.s64 	%rd194, %rd192, %rd193;
	ld.global.u32 	%rd195, [%rd194];
	ld.global.u32 	%rd196, [%rd194+4];
	shl.b64 	%rd197, %rd196, 32;
	or.b64  	%rd198, %rd197, %rd195;
	add.s32 	%r87, %r322, 4;
	mul.wide.s32 	%rd201, %r87, 8;
	add.s64 	%rd202, %rd1, %rd201;
	st.local.u64 	[%rd202], %rd198;
	add.s32 	%r322, %r322, 1;

BB0_19:
	setp.lt.u32	%p12, %r5, 4;
	@%p12 bra 	BB0_22;

	mul.wide.s32 	%rd205, %r322, 8;
	add.s64 	%rd700, %rd1, %rd205;
	shl.b32 	%r88, %r322, 1;
	sub.s32 	%r325, %r42, %r88;
	cvta.to.global.u64 	%rd7, %rd121;

BB0_21:
	add.s32 	%r89, %r325, %r10;
	mul.wide.s32 	%rd206, %r89, 4;
	add.s64 	%rd207, %rd7, %rd206;
	ld.global.u32 	%rd208, [%rd207+-8];
	ld.global.u32 	%rd209, [%rd207+-4];
	shl.b64 	%rd210, %rd209, 32;
	or.b64  	%rd211, %rd210, %rd208;
	add.s64 	%rd9, %rd700, 32;
	ld.global.u32 	%rd212, [%rd207+-16];
	ld.global.u32 	%rd213, [%rd207+-12];
	ld.global.u32 	%rd214, [%rd207+-24];
	ld.global.u32 	%rd215, [%rd207+-20];
	ld.global.u32 	%rd216, [%rd207+-32];
	ld.global.u32 	%rd217, [%rd207+-28];
	st.local.u64 	[%rd700+32], %rd211;
	shl.b64 	%rd218, %rd213, 32;
	or.b64  	%rd219, %rd218, %rd212;
	st.local.u64 	[%rd700+40], %rd219;
	shl.b64 	%rd220, %rd215, 32;
	or.b64  	%rd221, %rd220, %rd214;
	st.local.u64 	[%rd700+48], %rd221;
	shl.b64 	%rd222, %rd217, 32;
	or.b64  	%rd223, %rd222, %rd216;
	st.local.u64 	[%rd700+56], %rd223;
	add.s32 	%r325, %r325, -8;
	add.s32 	%r322, %r322, 4;
	setp.lt.s32	%p13, %r322, %r4;
	mov.u64 	%rd700, %rd9;
	@%p13 bra 	BB0_21;

BB0_22:
	ld.param.u32 	%r314, [evaluateFunction_param_6];
	ld.local.u64 	%rd241, [%rd1];
	{
	.reg .b32 %temp; 
	mov.b64 	{%r91, %temp}, %rd241;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r92}, %rd241;
	}
	mov.u32 	%r93, 291;
	mov.u32 	%r327, 0;
	prmt.b32 	%r94, %r91, %r327, %r93;
	prmt.b32 	%r95, %r92, %r327, %r93;
	mov.b64 	%rd726, {%r95, %r94};
	ld.local.u64 	%rd242, [%rd1+8];
	ld.local.u64 	%rd243, [%rd1+16];
	ld.local.u64 	%rd244, [%rd1+24];
	ld.local.u64 	%rd245, [%rd1+32];
	ld.local.u64 	%rd246, [%rd1+40];
	ld.local.u64 	%rd247, [%rd1+48];
	ld.local.u64 	%rd248, [%rd1+56];
	st.local.u64 	[%rd1], %rd726;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r96, %temp}, %rd242;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %rd242;
	}
	prmt.b32 	%r98, %r96, %r327, %r93;
	prmt.b32 	%r99, %r97, %r327, %r93;
	mov.b64 	%rd731, {%r99, %r98};
	st.local.u64 	[%rd1+8], %rd731;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %rd243;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r101}, %rd243;
	}
	prmt.b32 	%r102, %r100, %r327, %r93;
	prmt.b32 	%r103, %r101, %r327, %r93;
	mov.b64 	%rd736, {%r103, %r102};
	st.local.u64 	[%rd1+16], %rd736;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r104, %temp}, %rd244;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r105}, %rd244;
	}
	prmt.b32 	%r106, %r104, %r327, %r93;
	prmt.b32 	%r107, %r105, %r327, %r93;
	mov.b64 	%rd741, {%r107, %r106};
	st.local.u64 	[%rd1+24], %rd741;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r108, %temp}, %rd245;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r109}, %rd245;
	}
	prmt.b32 	%r110, %r108, %r327, %r93;
	prmt.b32 	%r111, %r109, %r327, %r93;
	mov.b64 	%rd746, {%r111, %r110};
	st.local.u64 	[%rd1+32], %rd746;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r112, %temp}, %rd246;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %rd246;
	}
	prmt.b32 	%r114, %r112, %r327, %r93;
	prmt.b32 	%r115, %r113, %r327, %r93;
	mov.b64 	%rd727, {%r115, %r114};
	st.local.u64 	[%rd1+40], %rd727;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r116, %temp}, %rd247;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r117}, %rd247;
	}
	prmt.b32 	%r118, %r116, %r327, %r93;
	prmt.b32 	%r119, %r117, %r327, %r93;
	mov.b64 	%rd732, {%r119, %r118};
	st.local.u64 	[%rd1+48], %rd732;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r120, %temp}, %rd248;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %rd248;
	}
	prmt.b32 	%r122, %r120, %r327, %r93;
	prmt.b32 	%r123, %r121, %r327, %r93;
	mov.b64 	%rd737, {%r123, %r122};
	st.local.u64 	[%rd1+56], %rd737;
	mov.u64 	%rd742, 31;
	st.local.u64 	[%rd1+64], %rd742;
	mov.u64 	%rd728, 0;
	st.local.u64 	[%rd1+72], %rd728;
	st.local.u64 	[%rd1+80], %rd728;
	st.local.u64 	[%rd1+88], %rd728;
	st.local.u64 	[%rd1+96], %rd728;
	st.local.u64 	[%rd1+104], %rd728;
	st.local.u64 	[%rd1+112], %rd728;
	st.local.u64 	[%rd1+120], %rd728;
	mov.u64 	%rd734, -9223372036854775808;
	st.local.u64 	[%rd1+128], %rd734;
	st.local.u64 	[%rd1+136], %rd728;
	st.local.u64 	[%rd1+144], %rd728;
	st.local.u64 	[%rd1+152], %rd728;
	st.local.u64 	[%rd1+160], %rd728;
	st.local.u64 	[%rd1+168], %rd728;
	st.local.u64 	[%rd1+176], %rd728;
	st.local.u64 	[%rd1+184], %rd728;
	st.local.u64 	[%rd1+192], %rd728;
	mad.lo.s32 	%r124, %r7, %r41, %r9;
	mul.lo.s32 	%r31, %r124, %r314;
	mov.u64 	%rd729, %rd728;
	mov.u64 	%rd730, %rd728;
	mov.u64 	%rd733, %rd728;
	mov.u64 	%rd735, %rd728;
	mov.u64 	%rd738, %rd728;
	mov.u64 	%rd739, %rd728;
	mov.u64 	%rd740, %rd728;
	mov.u64 	%rd743, %rd728;
	mov.u64 	%rd744, %rd728;
	mov.u64 	%rd745, %rd728;
	mov.u64 	%rd747, %rd728;
	mov.u64 	%rd748, %rd728;
	mov.u64 	%rd749, %rd728;
	mov.u64 	%rd750, %rd728;

BB0_23:
	ld.param.u64 	%rd696, [evaluateFunction_param_8];
	mov.u32 	%r311, 291;
	mov.u32 	%r310, 0;
	xor.b64  	%rd249, %rd729, %rd730;
	xor.b64  	%rd250, %rd249, %rd728;
	xor.b64  	%rd251, %rd250, %rd727;
	xor.b64  	%rd252, %rd251, %rd726;
	xor.b64  	%rd253, %rd734, %rd735;
	xor.b64  	%rd254, %rd253, %rd733;
	xor.b64  	%rd255, %rd254, %rd732;
	xor.b64  	%rd256, %rd255, %rd731;
	xor.b64  	%rd257, %rd739, %rd740;
	xor.b64  	%rd258, %rd257, %rd738;
	xor.b64  	%rd259, %rd258, %rd737;
	xor.b64  	%rd260, %rd259, %rd736;
	xor.b64  	%rd261, %rd744, %rd745;
	xor.b64  	%rd262, %rd261, %rd743;
	xor.b64  	%rd263, %rd262, %rd742;
	xor.b64  	%rd264, %rd263, %rd741;
	xor.b64  	%rd265, %rd749, %rd750;
	xor.b64  	%rd266, %rd265, %rd748;
	xor.b64  	%rd267, %rd266, %rd747;
	xor.b64  	%rd268, %rd267, %rd746;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd252, 1;
	shr.b64 	%rhs, %rd252, 63;
	add.u64 	%rd269, %lhs, %rhs;
	}
	xor.b64  	%rd270, %rd269, %rd264;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd256, 1;
	shr.b64 	%rhs, %rd256, 63;
	add.u64 	%rd271, %lhs, %rhs;
	}
	xor.b64  	%rd272, %rd271, %rd268;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd260, 1;
	shr.b64 	%rhs, %rd260, 63;
	add.u64 	%rd273, %lhs, %rhs;
	}
	xor.b64  	%rd274, %rd273, %rd252;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd264, 1;
	shr.b64 	%rhs, %rd264, 63;
	add.u64 	%rd275, %lhs, %rhs;
	}
	xor.b64  	%rd276, %rd275, %rd256;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd268, 1;
	shr.b64 	%rhs, %rd268, 63;
	add.u64 	%rd277, %lhs, %rhs;
	}
	xor.b64  	%rd278, %rd277, %rd260;
	xor.b64  	%rd279, %rd272, %rd726;
	xor.b64  	%rd280, %rd272, %rd727;
	xor.b64  	%rd281, %rd272, %rd728;
	xor.b64  	%rd282, %rd272, %rd729;
	xor.b64  	%rd283, %rd272, %rd730;
	xor.b64  	%rd284, %rd274, %rd731;
	xor.b64  	%rd285, %rd274, %rd732;
	xor.b64  	%rd286, %rd274, %rd733;
	xor.b64  	%rd287, %rd274, %rd734;
	xor.b64  	%rd288, %rd274, %rd735;
	xor.b64  	%rd289, %rd276, %rd736;
	xor.b64  	%rd290, %rd276, %rd737;
	xor.b64  	%rd291, %rd276, %rd738;
	xor.b64  	%rd292, %rd276, %rd739;
	xor.b64  	%rd293, %rd276, %rd740;
	xor.b64  	%rd294, %rd278, %rd741;
	xor.b64  	%rd295, %rd278, %rd742;
	xor.b64  	%rd296, %rd278, %rd743;
	xor.b64  	%rd297, %rd278, %rd744;
	xor.b64  	%rd298, %rd278, %rd745;
	xor.b64  	%rd299, %rd270, %rd746;
	xor.b64  	%rd300, %rd270, %rd747;
	xor.b64  	%rd301, %rd270, %rd748;
	xor.b64  	%rd302, %rd270, %rd749;
	xor.b64  	%rd303, %rd270, %rd750;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd280, 36;
	shr.b64 	%rhs, %rd280, 28;
	add.u64 	%rd304, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd281, 3;
	shr.b64 	%rhs, %rd281, 61;
	add.u64 	%rd305, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd282, 41;
	shr.b64 	%rhs, %rd282, 23;
	add.u64 	%rd306, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd283, 18;
	shr.b64 	%rhs, %rd283, 46;
	add.u64 	%rd307, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd284, 1;
	shr.b64 	%rhs, %rd284, 63;
	add.u64 	%rd308, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd285, 44;
	shr.b64 	%rhs, %rd285, 20;
	add.u64 	%rd309, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd286, 10;
	shr.b64 	%rhs, %rd286, 54;
	add.u64 	%rd310, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd287, 45;
	shr.b64 	%rhs, %rd287, 19;
	add.u64 	%rd311, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd288, 2;
	shr.b64 	%rhs, %rd288, 62;
	add.u64 	%rd312, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd289, 62;
	shr.b64 	%rhs, %rd289, 2;
	add.u64 	%rd313, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd290, 6;
	shr.b64 	%rhs, %rd290, 58;
	add.u64 	%rd314, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd291, 43;
	shr.b64 	%rhs, %rd291, 21;
	add.u64 	%rd315, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd292, 15;
	shr.b64 	%rhs, %rd292, 49;
	add.u64 	%rd316, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd293, 61;
	shr.b64 	%rhs, %rd293, 3;
	add.u64 	%rd317, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd294, 28;
	shr.b64 	%rhs, %rd294, 36;
	add.u64 	%rd318, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd295, 55;
	shr.b64 	%rhs, %rd295, 9;
	add.u64 	%rd319, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd296, 25;
	shr.b64 	%rhs, %rd296, 39;
	add.u64 	%rd320, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd297, 21;
	shr.b64 	%rhs, %rd297, 43;
	add.u64 	%rd321, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd298, 56;
	shr.b64 	%rhs, %rd298, 8;
	add.u64 	%rd322, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd299, 27;
	shr.b64 	%rhs, %rd299, 37;
	add.u64 	%rd323, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd300, 20;
	shr.b64 	%rhs, %rd300, 44;
	add.u64 	%rd324, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd301, 39;
	shr.b64 	%rhs, %rd301, 25;
	add.u64 	%rd325, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd302, 8;
	shr.b64 	%rhs, %rd302, 56;
	add.u64 	%rd326, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd303, 14;
	shr.b64 	%rhs, %rd303, 50;
	add.u64 	%rd327, %lhs, %rhs;
	}
	not.b64 	%rd328, %rd309;
	and.b64  	%rd329, %rd315, %rd328;
	xor.b64  	%rd330, %rd329, %rd279;
	not.b64 	%rd331, %rd324;
	and.b64  	%rd332, %rd305, %rd331;
	xor.b64  	%rd727, %rd332, %rd318;
	not.b64 	%rd333, %rd314;
	and.b64  	%rd334, %rd320, %rd333;
	xor.b64  	%rd728, %rd334, %rd308;
	not.b64 	%rd335, %rd304;
	and.b64  	%rd336, %rd310, %rd335;
	xor.b64  	%rd729, %rd323, %rd336;
	not.b64 	%rd337, %rd319;
	and.b64  	%rd338, %rd325, %rd337;
	xor.b64  	%rd730, %rd338, %rd313;
	not.b64 	%rd339, %rd315;
	and.b64  	%rd340, %rd321, %rd339;
	xor.b64  	%rd731, %rd340, %rd309;
	not.b64 	%rd341, %rd305;
	and.b64  	%rd342, %rd311, %rd341;
	xor.b64  	%rd732, %rd324, %rd342;
	not.b64 	%rd343, %rd320;
	and.b64  	%rd344, %rd326, %rd343;
	xor.b64  	%rd733, %rd344, %rd314;
	not.b64 	%rd345, %rd310;
	and.b64  	%rd346, %rd316, %rd345;
	xor.b64  	%rd734, %rd346, %rd304;
	not.b64 	%rd347, %rd325;
	and.b64  	%rd348, %rd306, %rd347;
	xor.b64  	%rd735, %rd348, %rd319;
	not.b64 	%rd349, %rd321;
	and.b64  	%rd350, %rd327, %rd349;
	xor.b64  	%rd736, %rd350, %rd315;
	not.b64 	%rd351, %rd311;
	and.b64  	%rd352, %rd317, %rd351;
	xor.b64  	%rd737, %rd352, %rd305;
	not.b64 	%rd353, %rd326;
	and.b64  	%rd354, %rd307, %rd353;
	xor.b64  	%rd738, %rd354, %rd320;
	not.b64 	%rd355, %rd316;
	and.b64  	%rd356, %rd322, %rd355;
	xor.b64  	%rd739, %rd356, %rd310;
	not.b64 	%rd357, %rd306;
	and.b64  	%rd358, %rd312, %rd357;
	xor.b64  	%rd740, %rd325, %rd358;
	not.b64 	%rd359, %rd327;
	and.b64  	%rd360, %rd279, %rd359;
	xor.b64  	%rd741, %rd360, %rd321;
	not.b64 	%rd361, %rd317;
	and.b64  	%rd362, %rd318, %rd361;
	xor.b64  	%rd742, %rd362, %rd311;
	not.b64 	%rd363, %rd307;
	and.b64  	%rd364, %rd308, %rd363;
	xor.b64  	%rd743, %rd326, %rd364;
	not.b64 	%rd365, %rd322;
	and.b64  	%rd366, %rd323, %rd365;
	xor.b64  	%rd744, %rd366, %rd316;
	not.b64 	%rd367, %rd312;
	and.b64  	%rd368, %rd313, %rd367;
	xor.b64  	%rd745, %rd368, %rd306;
	not.b64 	%rd369, %rd279;
	and.b64  	%rd370, %rd309, %rd369;
	xor.b64  	%rd746, %rd327, %rd370;
	not.b64 	%rd371, %rd318;
	and.b64  	%rd372, %rd324, %rd371;
	xor.b64  	%rd747, %rd372, %rd317;
	not.b64 	%rd373, %rd308;
	and.b64  	%rd374, %rd314, %rd373;
	xor.b64  	%rd748, %rd374, %rd307;
	not.b64 	%rd375, %rd323;
	and.b64  	%rd376, %rd304, %rd375;
	xor.b64  	%rd749, %rd376, %rd322;
	not.b64 	%rd377, %rd313;
	and.b64  	%rd378, %rd319, %rd377;
	xor.b64  	%rd750, %rd378, %rd312;
	mul.wide.s32 	%rd379, %r327, 8;
	mov.u64 	%rd380, K;
	add.s64 	%rd381, %rd380, %rd379;
	ld.const.u64 	%rd67, [%rd381];
	xor.b64  	%rd726, %rd330, %rd67;
	add.s32 	%r125, %r327, %r31;
	mul.lo.s32 	%r126, %r125, %r44;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r127, %temp}, %rd726;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r128}, %rd726;
	}
	prmt.b32 	%r131, %r127, %r310, %r311;
	prmt.b32 	%r132, %r128, %r310, %r311;
	mov.b64 	%rd382, {%r132, %r131};
	shr.u64 	%rd383, %rd382, 32;
	cvta.to.global.u64 	%rd384, %rd696;
	mul.wide.s32 	%rd385, %r126, 4;
	add.s64 	%rd69, %rd384, %rd385;
	st.global.u32 	[%rd69+252], %rd383;
	st.global.u32 	[%rd69+248], %rd382;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r133, %temp}, %rd731;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r134}, %rd731;
	}
	prmt.b32 	%r135, %r133, %r310, %r311;
	prmt.b32 	%r136, %r134, %r310, %r311;
	mov.b64 	%rd386, {%r136, %r135};
	shr.u64 	%rd387, %rd386, 32;
	st.global.u32 	[%rd69+244], %rd387;
	st.global.u32 	[%rd69+240], %rd386;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r137, %temp}, %rd736;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r138}, %rd736;
	}
	prmt.b32 	%r139, %r137, %r310, %r311;
	prmt.b32 	%r140, %r138, %r310, %r311;
	mov.b64 	%rd388, {%r140, %r139};
	shr.u64 	%rd389, %rd388, 32;
	st.global.u32 	[%rd69+236], %rd389;
	st.global.u32 	[%rd69+232], %rd388;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r141, %temp}, %rd741;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r142}, %rd741;
	}
	prmt.b32 	%r143, %r141, %r310, %r311;
	prmt.b32 	%r144, %r142, %r310, %r311;
	mov.b64 	%rd390, {%r144, %r143};
	shr.u64 	%rd391, %rd390, 32;
	st.global.u32 	[%rd69+228], %rd391;
	st.global.u32 	[%rd69+224], %rd390;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r145, %temp}, %rd746;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r146}, %rd746;
	}
	prmt.b32 	%r147, %r145, %r310, %r311;
	prmt.b32 	%r148, %r146, %r310, %r311;
	mov.b64 	%rd392, {%r148, %r147};
	shr.u64 	%rd393, %rd392, 32;
	st.global.u32 	[%rd69+220], %rd393;
	st.global.u32 	[%rd69+216], %rd392;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r149, %temp}, %rd727;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r150}, %rd727;
	}
	prmt.b32 	%r151, %r149, %r310, %r311;
	prmt.b32 	%r152, %r150, %r310, %r311;
	mov.b64 	%rd394, {%r152, %r151};
	shr.u64 	%rd395, %rd394, 32;
	st.global.u32 	[%rd69+212], %rd395;
	st.global.u32 	[%rd69+208], %rd394;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %rd732;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r154}, %rd732;
	}
	prmt.b32 	%r155, %r153, %r310, %r311;
	prmt.b32 	%r156, %r154, %r310, %r311;
	mov.b64 	%rd396, {%r156, %r155};
	shr.u64 	%rd397, %rd396, 32;
	st.global.u32 	[%rd69+204], %rd397;
	st.global.u32 	[%rd69+200], %rd396;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r157, %temp}, %rd737;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r158}, %rd737;
	}
	prmt.b32 	%r159, %r157, %r310, %r311;
	prmt.b32 	%r160, %r158, %r310, %r311;
	mov.b64 	%rd398, {%r160, %r159};
	shr.u64 	%rd399, %rd398, 32;
	st.global.u32 	[%rd69+196], %rd399;
	st.global.u32 	[%rd69+192], %rd398;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r161, %temp}, %rd742;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r162}, %rd742;
	}
	prmt.b32 	%r163, %r161, %r310, %r311;
	prmt.b32 	%r164, %r162, %r310, %r311;
	mov.b64 	%rd400, {%r164, %r163};
	shr.u64 	%rd401, %rd400, 32;
	st.global.u32 	[%rd69+188], %rd401;
	st.global.u32 	[%rd69+184], %rd400;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r165, %temp}, %rd747;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r166}, %rd747;
	}
	prmt.b32 	%r167, %r165, %r310, %r311;
	prmt.b32 	%r168, %r166, %r310, %r311;
	mov.b64 	%rd402, {%r168, %r167};
	shr.u64 	%rd403, %rd402, 32;
	st.global.u32 	[%rd69+180], %rd403;
	st.global.u32 	[%rd69+176], %rd402;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r169, %temp}, %rd728;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r170}, %rd728;
	}
	prmt.b32 	%r171, %r169, %r310, %r311;
	prmt.b32 	%r172, %r170, %r310, %r311;
	mov.b64 	%rd404, {%r172, %r171};
	shr.u64 	%rd405, %rd404, 32;
	st.global.u32 	[%rd69+172], %rd405;
	st.global.u32 	[%rd69+168], %rd404;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r173, %temp}, %rd733;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r174}, %rd733;
	}
	prmt.b32 	%r175, %r173, %r310, %r311;
	prmt.b32 	%r176, %r174, %r310, %r311;
	mov.b64 	%rd406, {%r176, %r175};
	shr.u64 	%rd407, %rd406, 32;
	st.global.u32 	[%rd69+164], %rd407;
	st.global.u32 	[%rd69+160], %rd406;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r177, %temp}, %rd738;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r178}, %rd738;
	}
	prmt.b32 	%r179, %r177, %r310, %r311;
	prmt.b32 	%r180, %r178, %r310, %r311;
	mov.b64 	%rd408, {%r180, %r179};
	shr.u64 	%rd409, %rd408, 32;
	st.global.u32 	[%rd69+156], %rd409;
	st.global.u32 	[%rd69+152], %rd408;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r181, %temp}, %rd743;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r182}, %rd743;
	}
	prmt.b32 	%r183, %r181, %r310, %r311;
	prmt.b32 	%r184, %r182, %r310, %r311;
	mov.b64 	%rd410, {%r184, %r183};
	shr.u64 	%rd411, %rd410, 32;
	st.global.u32 	[%rd69+148], %rd411;
	st.global.u32 	[%rd69+144], %rd410;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r185, %temp}, %rd748;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r186}, %rd748;
	}
	prmt.b32 	%r187, %r185, %r310, %r311;
	prmt.b32 	%r188, %r186, %r310, %r311;
	mov.b64 	%rd412, {%r188, %r187};
	shr.u64 	%rd413, %rd412, 32;
	st.global.u32 	[%rd69+140], %rd413;
	st.global.u32 	[%rd69+136], %rd412;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r189, %temp}, %rd729;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r190}, %rd729;
	}
	prmt.b32 	%r191, %r189, %r310, %r311;
	prmt.b32 	%r192, %r190, %r310, %r311;
	mov.b64 	%rd414, {%r192, %r191};
	shr.u64 	%rd415, %rd414, 32;
	st.global.u32 	[%rd69+132], %rd415;
	st.global.u32 	[%rd69+128], %rd414;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r193, %temp}, %rd734;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r194}, %rd734;
	}
	prmt.b32 	%r195, %r193, %r310, %r311;
	prmt.b32 	%r196, %r194, %r310, %r311;
	mov.b64 	%rd416, {%r196, %r195};
	shr.u64 	%rd417, %rd416, 32;
	st.global.u32 	[%rd69+124], %rd417;
	st.global.u32 	[%rd69+120], %rd416;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r197, %temp}, %rd739;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r198}, %rd739;
	}
	prmt.b32 	%r199, %r197, %r310, %r311;
	prmt.b32 	%r200, %r198, %r310, %r311;
	mov.b64 	%rd418, {%r200, %r199};
	shr.u64 	%rd419, %rd418, 32;
	st.global.u32 	[%rd69+116], %rd419;
	st.global.u32 	[%rd69+112], %rd418;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r201, %temp}, %rd744;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r202}, %rd744;
	}
	prmt.b32 	%r203, %r201, %r310, %r311;
	prmt.b32 	%r204, %r202, %r310, %r311;
	mov.b64 	%rd420, {%r204, %r203};
	shr.u64 	%rd421, %rd420, 32;
	st.global.u32 	[%rd69+108], %rd421;
	st.global.u32 	[%rd69+104], %rd420;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r205, %temp}, %rd749;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r206}, %rd749;
	}
	prmt.b32 	%r207, %r205, %r310, %r311;
	prmt.b32 	%r208, %r206, %r310, %r311;
	mov.b64 	%rd422, {%r208, %r207};
	shr.u64 	%rd423, %rd422, 32;
	st.global.u32 	[%rd69+100], %rd423;
	st.global.u32 	[%rd69+96], %rd422;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r209, %temp}, %rd730;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r210}, %rd730;
	}
	prmt.b32 	%r211, %r209, %r310, %r311;
	prmt.b32 	%r212, %r210, %r310, %r311;
	mov.b64 	%rd424, {%r212, %r211};
	shr.u64 	%rd425, %rd424, 32;
	st.global.u32 	[%rd69+92], %rd425;
	st.global.u32 	[%rd69+88], %rd424;
	setp.eq.s32	%p14, %r327, 23;
	@%p14 bra 	BB0_25;

	mov.u32 	%r309, 291;
	xor.b64  	%rd426, %rd729, %rd728;
	xor.b64  	%rd427, %rd426, %rd727;
	xor.b64  	%rd428, %rd427, %rd730;
	xor.b64  	%rd429, %rd428, %rd726;
	xor.b64  	%rd430, %rd731, %rd734;
	xor.b64  	%rd431, %rd430, %rd732;
	xor.b64  	%rd432, %rd431, %rd735;
	xor.b64  	%rd433, %rd432, %rd733;
	xor.b64  	%rd434, %rd739, %rd737;
	xor.b64  	%rd435, %rd434, %rd740;
	xor.b64  	%rd436, %rd435, %rd738;
	xor.b64  	%rd437, %rd436, %rd736;
	xor.b64  	%rd438, %rd742, %rd745;
	xor.b64  	%rd439, %rd438, %rd744;
	xor.b64  	%rd440, %rd439, %rd743;
	xor.b64  	%rd441, %rd440, %rd741;
	xor.b64  	%rd442, %rd750, %rd748;
	xor.b64  	%rd443, %rd442, %rd749;
	xor.b64  	%rd444, %rd443, %rd747;
	xor.b64  	%rd445, %rd444, %rd746;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd429, 1;
	shr.b64 	%rhs, %rd429, 63;
	add.u64 	%rd446, %lhs, %rhs;
	}
	xor.b64  	%rd447, %rd446, %rd441;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd433, 1;
	shr.b64 	%rhs, %rd433, 63;
	add.u64 	%rd448, %lhs, %rhs;
	}
	xor.b64  	%rd449, %rd448, %rd445;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd437, 1;
	shr.b64 	%rhs, %rd437, 63;
	add.u64 	%rd450, %lhs, %rhs;
	}
	xor.b64  	%rd451, %rd450, %rd429;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd441, 1;
	shr.b64 	%rhs, %rd441, 63;
	add.u64 	%rd452, %lhs, %rhs;
	}
	xor.b64  	%rd453, %rd452, %rd433;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd445, 1;
	shr.b64 	%rhs, %rd445, 63;
	add.u64 	%rd454, %lhs, %rhs;
	}
	xor.b64  	%rd455, %rd454, %rd437;
	xor.b64  	%rd456, %rd449, %rd726;
	xor.b64  	%rd457, %rd449, %rd728;
	xor.b64  	%rd458, %rd451, %rd731;
	xor.b64  	%rd459, %rd451, %rd732;
	xor.b64  	%rd460, %rd451, %rd734;
	xor.b64  	%rd461, %rd453, %rd737;
	xor.b64  	%rd462, %rd453, %rd738;
	xor.b64  	%rd463, %rd453, %rd740;
	xor.b64  	%rd464, %rd455, %rd741;
	xor.b64  	%rd465, %rd455, %rd743;
	xor.b64  	%rd466, %rd455, %rd744;
	xor.b64  	%rd467, %rd447, %rd747;
	xor.b64  	%rd468, %rd447, %rd750;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd457, 3;
	shr.b64 	%rhs, %rd457, 61;
	add.u64 	%rd469, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd458, 1;
	shr.b64 	%rhs, %rd458, 63;
	add.u64 	%rd470, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd459, 44;
	shr.b64 	%rhs, %rd459, 20;
	add.u64 	%rd471, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd460, 45;
	shr.b64 	%rhs, %rd460, 19;
	add.u64 	%rd472, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd461, 6;
	shr.b64 	%rhs, %rd461, 58;
	add.u64 	%rd473, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd462, 43;
	shr.b64 	%rhs, %rd462, 21;
	add.u64 	%rd474, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd463, 61;
	shr.b64 	%rhs, %rd463, 3;
	add.u64 	%rd475, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd464, 28;
	shr.b64 	%rhs, %rd464, 36;
	add.u64 	%rd476, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd465, 25;
	shr.b64 	%rhs, %rd465, 39;
	add.u64 	%rd477, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd466, 21;
	shr.b64 	%rhs, %rd466, 43;
	add.u64 	%rd478, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd467, 20;
	shr.b64 	%rhs, %rd467, 44;
	add.u64 	%rd479, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd468, 14;
	shr.b64 	%rhs, %rd468, 50;
	add.u64 	%rd480, %lhs, %rhs;
	}
	not.b64 	%rd481, %rd471;
	and.b64  	%rd482, %rd474, %rd481;
	xor.b64  	%rd483, %rd482, %rd456;
	not.b64 	%rd484, %rd479;
	and.b64  	%rd485, %rd469, %rd484;
	xor.b64  	%rd486, %rd485, %rd476;
	not.b64 	%rd487, %rd473;
	and.b64  	%rd488, %rd477, %rd487;
	xor.b64  	%rd489, %rd488, %rd470;
	not.b64 	%rd490, %rd474;
	and.b64  	%rd491, %rd478, %rd490;
	xor.b64  	%rd492, %rd491, %rd471;
	not.b64 	%rd493, %rd469;
	and.b64  	%rd494, %rd472, %rd493;
	xor.b64  	%rd495, %rd479, %rd494;
	not.b64 	%rd496, %rd478;
	and.b64  	%rd497, %rd480, %rd496;
	xor.b64  	%rd498, %rd497, %rd474;
	not.b64 	%rd499, %rd472;
	and.b64  	%rd500, %rd475, %rd499;
	xor.b64  	%rd501, %rd500, %rd469;
	not.b64 	%rd502, %rd480;
	and.b64  	%rd503, %rd456, %rd502;
	xor.b64  	%rd504, %rd503, %rd478;
	not.b64 	%rd505, %rd475;
	and.b64  	%rd506, %rd476, %rd505;
	xor.b64  	%rd507, %rd506, %rd472;
	not.b64 	%rd508, %rd456;
	and.b64  	%rd509, %rd471, %rd508;
	xor.b64  	%rd510, %rd480, %rd509;
	not.b64 	%rd511, %rd476;
	and.b64  	%rd512, %rd479, %rd511;
	xor.b64  	%rd513, %rd512, %rd475;
	xor.b64  	%rd514, %rd483, %rd67;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r213, %temp}, %rd514;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r214}, %rd514;
	}
	mov.u32 	%r216, 0;
	prmt.b32 	%r217, %r213, %r216, %r309;
	prmt.b32 	%r218, %r214, %r216, %r309;
	mov.b64 	%rd515, {%r218, %r217};
	shr.u64 	%rd516, %rd515, 32;
	st.global.u32 	[%rd69+84], %rd516;
	st.global.u32 	[%rd69+80], %rd515;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r219, %temp}, %rd492;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r220}, %rd492;
	}
	prmt.b32 	%r221, %r219, %r216, %r309;
	prmt.b32 	%r222, %r220, %r216, %r309;
	mov.b64 	%rd517, {%r222, %r221};
	shr.u64 	%rd518, %rd517, 32;
	st.global.u32 	[%rd69+76], %rd518;
	st.global.u32 	[%rd69+72], %rd517;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r223, %temp}, %rd498;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r224}, %rd498;
	}
	prmt.b32 	%r225, %r223, %r216, %r309;
	prmt.b32 	%r226, %r224, %r216, %r309;
	mov.b64 	%rd519, {%r226, %r225};
	shr.u64 	%rd520, %rd519, 32;
	st.global.u32 	[%rd69+68], %rd520;
	st.global.u32 	[%rd69+64], %rd519;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r227, %temp}, %rd504;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r228}, %rd504;
	}
	prmt.b32 	%r229, %r227, %r216, %r309;
	prmt.b32 	%r230, %r228, %r216, %r309;
	mov.b64 	%rd521, {%r230, %r229};
	shr.u64 	%rd522, %rd521, 32;
	st.global.u32 	[%rd69+60], %rd522;
	st.global.u32 	[%rd69+56], %rd521;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r231, %temp}, %rd510;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r232}, %rd510;
	}
	prmt.b32 	%r233, %r231, %r216, %r309;
	prmt.b32 	%r234, %r232, %r216, %r309;
	mov.b64 	%rd523, {%r234, %r233};
	shr.u64 	%rd524, %rd523, 32;
	st.global.u32 	[%rd69+52], %rd524;
	st.global.u32 	[%rd69+48], %rd523;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r235, %temp}, %rd486;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r236}, %rd486;
	}
	prmt.b32 	%r237, %r235, %r216, %r309;
	prmt.b32 	%r238, %r236, %r216, %r309;
	mov.b64 	%rd525, {%r238, %r237};
	shr.u64 	%rd526, %rd525, 32;
	st.global.u32 	[%rd69+44], %rd526;
	st.global.u32 	[%rd69+40], %rd525;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r239, %temp}, %rd495;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r240}, %rd495;
	}
	prmt.b32 	%r241, %r239, %r216, %r309;
	prmt.b32 	%r242, %r240, %r216, %r309;
	mov.b64 	%rd527, {%r242, %r241};
	shr.u64 	%rd528, %rd527, 32;
	st.global.u32 	[%rd69+36], %rd528;
	st.global.u32 	[%rd69+32], %rd527;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r243, %temp}, %rd501;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r244}, %rd501;
	}
	prmt.b32 	%r245, %r243, %r216, %r309;
	prmt.b32 	%r246, %r244, %r216, %r309;
	mov.b64 	%rd529, {%r246, %r245};
	shr.u64 	%rd530, %rd529, 32;
	st.global.u32 	[%rd69+28], %rd530;
	st.global.u32 	[%rd69+24], %rd529;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r247, %temp}, %rd507;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r248}, %rd507;
	}
	prmt.b32 	%r249, %r247, %r216, %r309;
	prmt.b32 	%r250, %r248, %r216, %r309;
	mov.b64 	%rd531, {%r250, %r249};
	shr.u64 	%rd532, %rd531, 32;
	st.global.u32 	[%rd69+20], %rd532;
	st.global.u32 	[%rd69+16], %rd531;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r251, %temp}, %rd513;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r252}, %rd513;
	}
	prmt.b32 	%r253, %r251, %r216, %r309;
	prmt.b32 	%r254, %r252, %r216, %r309;
	mov.b64 	%rd533, {%r254, %r253};
	shr.u64 	%rd534, %rd533, 32;
	st.global.u32 	[%rd69+12], %rd534;
	st.global.u32 	[%rd69+8], %rd533;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r255, %temp}, %rd489;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r256}, %rd489;
	}
	prmt.b32 	%r257, %r255, %r216, %r309;
	prmt.b32 	%r258, %r256, %r216, %r309;
	mov.b64 	%rd535, {%r258, %r257};
	shr.u64 	%rd536, %rd535, 32;
	st.global.u32 	[%rd69+4], %rd536;
	st.global.u32 	[%rd69], %rd535;

BB0_25:
	add.s32 	%r327, %r327, 1;
	mov.u32 	%r328, 0;
	mov.u32 	%r35, %nctaid.x;
	setp.ne.s32	%p15, %r327, 24;
	@%p15 bra 	BB0_23;

BB0_26:
	mov.u64 	%rd697, K;
	xor.b64  	%rd537, %rd729, %rd730;
	xor.b64  	%rd538, %rd537, %rd728;
	xor.b64  	%rd539, %rd538, %rd727;
	xor.b64  	%rd540, %rd539, %rd726;
	xor.b64  	%rd541, %rd734, %rd735;
	xor.b64  	%rd542, %rd541, %rd733;
	xor.b64  	%rd543, %rd542, %rd732;
	xor.b64  	%rd544, %rd543, %rd731;
	xor.b64  	%rd545, %rd739, %rd740;
	xor.b64  	%rd546, %rd545, %rd738;
	xor.b64  	%rd547, %rd546, %rd737;
	xor.b64  	%rd548, %rd547, %rd736;
	xor.b64  	%rd549, %rd744, %rd745;
	xor.b64  	%rd550, %rd549, %rd743;
	xor.b64  	%rd551, %rd550, %rd742;
	xor.b64  	%rd552, %rd551, %rd741;
	xor.b64  	%rd553, %rd749, %rd750;
	xor.b64  	%rd554, %rd553, %rd748;
	xor.b64  	%rd555, %rd554, %rd747;
	xor.b64  	%rd556, %rd555, %rd746;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd540, 1;
	shr.b64 	%rhs, %rd540, 63;
	add.u64 	%rd557, %lhs, %rhs;
	}
	xor.b64  	%rd558, %rd557, %rd552;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd544, 1;
	shr.b64 	%rhs, %rd544, 63;
	add.u64 	%rd559, %lhs, %rhs;
	}
	xor.b64  	%rd560, %rd559, %rd556;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd548, 1;
	shr.b64 	%rhs, %rd548, 63;
	add.u64 	%rd561, %lhs, %rhs;
	}
	xor.b64  	%rd562, %rd561, %rd540;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd552, 1;
	shr.b64 	%rhs, %rd552, 63;
	add.u64 	%rd563, %lhs, %rhs;
	}
	xor.b64  	%rd564, %rd563, %rd544;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd556, 1;
	shr.b64 	%rhs, %rd556, 63;
	add.u64 	%rd565, %lhs, %rhs;
	}
	xor.b64  	%rd566, %rd565, %rd548;
	xor.b64  	%rd567, %rd560, %rd726;
	xor.b64  	%rd568, %rd560, %rd727;
	xor.b64  	%rd569, %rd560, %rd728;
	xor.b64  	%rd570, %rd560, %rd729;
	xor.b64  	%rd571, %rd560, %rd730;
	xor.b64  	%rd572, %rd562, %rd731;
	xor.b64  	%rd573, %rd562, %rd732;
	xor.b64  	%rd574, %rd562, %rd733;
	xor.b64  	%rd575, %rd562, %rd734;
	xor.b64  	%rd576, %rd562, %rd735;
	xor.b64  	%rd577, %rd564, %rd736;
	xor.b64  	%rd578, %rd564, %rd737;
	xor.b64  	%rd579, %rd564, %rd738;
	xor.b64  	%rd580, %rd564, %rd739;
	xor.b64  	%rd581, %rd564, %rd740;
	xor.b64  	%rd582, %rd566, %rd741;
	xor.b64  	%rd583, %rd566, %rd742;
	xor.b64  	%rd584, %rd566, %rd743;
	xor.b64  	%rd585, %rd566, %rd744;
	xor.b64  	%rd586, %rd566, %rd745;
	xor.b64  	%rd587, %rd558, %rd746;
	xor.b64  	%rd588, %rd558, %rd747;
	xor.b64  	%rd589, %rd558, %rd748;
	xor.b64  	%rd590, %rd558, %rd749;
	xor.b64  	%rd591, %rd558, %rd750;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd568, 36;
	shr.b64 	%rhs, %rd568, 28;
	add.u64 	%rd592, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd569, 3;
	shr.b64 	%rhs, %rd569, 61;
	add.u64 	%rd593, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd570, 41;
	shr.b64 	%rhs, %rd570, 23;
	add.u64 	%rd594, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd571, 18;
	shr.b64 	%rhs, %rd571, 46;
	add.u64 	%rd595, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd572, 1;
	shr.b64 	%rhs, %rd572, 63;
	add.u64 	%rd596, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd573, 44;
	shr.b64 	%rhs, %rd573, 20;
	add.u64 	%rd597, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd574, 10;
	shr.b64 	%rhs, %rd574, 54;
	add.u64 	%rd598, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd575, 45;
	shr.b64 	%rhs, %rd575, 19;
	add.u64 	%rd599, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd576, 2;
	shr.b64 	%rhs, %rd576, 62;
	add.u64 	%rd600, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd577, 62;
	shr.b64 	%rhs, %rd577, 2;
	add.u64 	%rd601, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd578, 6;
	shr.b64 	%rhs, %rd578, 58;
	add.u64 	%rd602, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd579, 43;
	shr.b64 	%rhs, %rd579, 21;
	add.u64 	%rd603, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd580, 15;
	shr.b64 	%rhs, %rd580, 49;
	add.u64 	%rd604, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd581, 61;
	shr.b64 	%rhs, %rd581, 3;
	add.u64 	%rd605, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd582, 28;
	shr.b64 	%rhs, %rd582, 36;
	add.u64 	%rd606, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd583, 55;
	shr.b64 	%rhs, %rd583, 9;
	add.u64 	%rd607, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd584, 25;
	shr.b64 	%rhs, %rd584, 39;
	add.u64 	%rd608, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd585, 21;
	shr.b64 	%rhs, %rd585, 43;
	add.u64 	%rd609, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd586, 56;
	shr.b64 	%rhs, %rd586, 8;
	add.u64 	%rd610, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd587, 27;
	shr.b64 	%rhs, %rd587, 37;
	add.u64 	%rd611, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd588, 20;
	shr.b64 	%rhs, %rd588, 44;
	add.u64 	%rd612, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd589, 39;
	shr.b64 	%rhs, %rd589, 25;
	add.u64 	%rd613, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd590, 8;
	shr.b64 	%rhs, %rd590, 56;
	add.u64 	%rd614, %lhs, %rhs;
	}
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd591, 14;
	shr.b64 	%rhs, %rd591, 50;
	add.u64 	%rd615, %lhs, %rhs;
	}
	not.b64 	%rd616, %rd597;
	and.b64  	%rd617, %rd603, %rd616;
	xor.b64  	%rd618, %rd617, %rd567;
	not.b64 	%rd619, %rd612;
	and.b64  	%rd620, %rd593, %rd619;
	xor.b64  	%rd727, %rd620, %rd606;
	not.b64 	%rd621, %rd602;
	and.b64  	%rd622, %rd608, %rd621;
	xor.b64  	%rd728, %rd622, %rd596;
	not.b64 	%rd623, %rd592;
	and.b64  	%rd624, %rd598, %rd623;
	xor.b64  	%rd729, %rd611, %rd624;
	not.b64 	%rd625, %rd607;
	and.b64  	%rd626, %rd613, %rd625;
	xor.b64  	%rd730, %rd626, %rd601;
	not.b64 	%rd627, %rd603;
	and.b64  	%rd628, %rd609, %rd627;
	xor.b64  	%rd731, %rd628, %rd597;
	not.b64 	%rd629, %rd593;
	and.b64  	%rd630, %rd599, %rd629;
	xor.b64  	%rd732, %rd612, %rd630;
	not.b64 	%rd631, %rd608;
	and.b64  	%rd632, %rd614, %rd631;
	xor.b64  	%rd733, %rd632, %rd602;
	not.b64 	%rd633, %rd598;
	and.b64  	%rd634, %rd604, %rd633;
	xor.b64  	%rd734, %rd634, %rd592;
	not.b64 	%rd635, %rd613;
	and.b64  	%rd636, %rd594, %rd635;
	xor.b64  	%rd735, %rd636, %rd607;
	not.b64 	%rd637, %rd609;
	and.b64  	%rd638, %rd615, %rd637;
	xor.b64  	%rd736, %rd638, %rd603;
	not.b64 	%rd639, %rd599;
	and.b64  	%rd640, %rd605, %rd639;
	xor.b64  	%rd737, %rd640, %rd593;
	not.b64 	%rd641, %rd614;
	and.b64  	%rd642, %rd595, %rd641;
	xor.b64  	%rd738, %rd642, %rd608;
	not.b64 	%rd643, %rd604;
	and.b64  	%rd644, %rd610, %rd643;
	xor.b64  	%rd739, %rd644, %rd598;
	not.b64 	%rd645, %rd594;
	and.b64  	%rd646, %rd600, %rd645;
	xor.b64  	%rd740, %rd613, %rd646;
	not.b64 	%rd647, %rd615;
	and.b64  	%rd648, %rd567, %rd647;
	xor.b64  	%rd741, %rd648, %rd609;
	not.b64 	%rd649, %rd605;
	and.b64  	%rd650, %rd606, %rd649;
	xor.b64  	%rd742, %rd650, %rd599;
	not.b64 	%rd651, %rd595;
	and.b64  	%rd652, %rd596, %rd651;
	xor.b64  	%rd743, %rd614, %rd652;
	not.b64 	%rd653, %rd610;
	and.b64  	%rd654, %rd611, %rd653;
	xor.b64  	%rd744, %rd654, %rd604;
	not.b64 	%rd655, %rd600;
	and.b64  	%rd656, %rd601, %rd655;
	xor.b64  	%rd745, %rd656, %rd594;
	not.b64 	%rd657, %rd567;
	and.b64  	%rd658, %rd597, %rd657;
	xor.b64  	%rd746, %rd615, %rd658;
	not.b64 	%rd659, %rd606;
	and.b64  	%rd660, %rd612, %rd659;
	xor.b64  	%rd747, %rd660, %rd605;
	not.b64 	%rd661, %rd596;
	and.b64  	%rd662, %rd602, %rd661;
	xor.b64  	%rd748, %rd662, %rd595;
	not.b64 	%rd663, %rd611;
	and.b64  	%rd664, %rd592, %rd663;
	xor.b64  	%rd749, %rd664, %rd610;
	not.b64 	%rd665, %rd601;
	and.b64  	%rd666, %rd607, %rd665;
	xor.b64  	%rd750, %rd666, %rd600;
	mul.wide.s32 	%rd667, %r328, 8;
	add.s64 	%rd669, %rd697, %rd667;
	ld.const.u64 	%rd670, [%rd669];
	xor.b64  	%rd726, %rd618, %rd670;
	add.s32 	%r328, %r328, 1;
	setp.ne.s32	%p16, %r328, 24;
	@%p16 bra 	BB0_26;

	mov.u32 	%r313, %ntid.x;
	cvta.to.global.u64 	%rd698, %rd696;
	mov.u32 	%r312, 291;
	add.s32 	%r260, %r31, 23;
	mul.lo.s32 	%r261, %r260, %r44;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r262, %temp}, %rd726;
	}
	mov.u32 	%r264, 0;
	prmt.b32 	%r265, %r262, %r264, %r312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r266}, %rd726;
	}
	prmt.b32 	%r267, %r266, %r264, %r312;
	mov.b64 	%rd672, {%r267, %r265};
	shr.u64 	%rd673, %rd672, 32;
	mul.wide.s32 	%rd674, %r261, 4;
	add.s64 	%rd675, %rd698, %rd674;
	st.global.u32 	[%rd675+84], %rd673;
	st.global.u32 	[%rd675+80], %rd672;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r268, %temp}, %rd731;
	}
	prmt.b32 	%r269, %r268, %r264, %r312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r270}, %rd731;
	}
	prmt.b32 	%r271, %r270, %r264, %r312;
	mov.b64 	%rd676, {%r271, %r269};
	shr.u64 	%rd677, %rd676, 32;
	st.global.u32 	[%rd675+76], %rd677;
	st.global.u32 	[%rd675+72], %rd676;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r272, %temp}, %rd736;
	}
	prmt.b32 	%r273, %r272, %r264, %r312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r274}, %rd736;
	}
	prmt.b32 	%r275, %r274, %r264, %r312;
	mov.b64 	%rd678, {%r275, %r273};
	shr.u64 	%rd679, %rd678, 32;
	st.global.u32 	[%rd675+68], %rd679;
	st.global.u32 	[%rd675+64], %rd678;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r276, %temp}, %rd741;
	}
	prmt.b32 	%r277, %r276, %r264, %r312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r278}, %rd741;
	}
	prmt.b32 	%r279, %r278, %r264, %r312;
	mov.b64 	%rd680, {%r279, %r277};
	shr.u64 	%rd681, %rd680, 32;
	st.global.u32 	[%rd675+60], %rd681;
	st.global.u32 	[%rd675+56], %rd680;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r280, %temp}, %rd746;
	}
	prmt.b32 	%r281, %r280, %r264, %r312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r282}, %rd746;
	}
	prmt.b32 	%r283, %r282, %r264, %r312;
	mov.b64 	%rd682, {%r283, %r281};
	shr.u64 	%rd683, %rd682, 32;
	st.global.u32 	[%rd675+52], %rd683;
	st.global.u32 	[%rd675+48], %rd682;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r284, %temp}, %rd727;
	}
	prmt.b32 	%r285, %r284, %r264, %r312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r286}, %rd727;
	}
	prmt.b32 	%r287, %r286, %r264, %r312;
	mov.b64 	%rd684, {%r287, %r285};
	shr.u64 	%rd685, %rd684, 32;
	st.global.u32 	[%rd675+44], %rd685;
	st.global.u32 	[%rd675+40], %rd684;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r288, %temp}, %rd732;
	}
	prmt.b32 	%r289, %r288, %r264, %r312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r290}, %rd732;
	}
	prmt.b32 	%r291, %r290, %r264, %r312;
	mov.b64 	%rd686, {%r291, %r289};
	shr.u64 	%rd687, %rd686, 32;
	st.global.u32 	[%rd675+36], %rd687;
	st.global.u32 	[%rd675+32], %rd686;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r292, %temp}, %rd737;
	}
	prmt.b32 	%r293, %r292, %r264, %r312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r294}, %rd737;
	}
	prmt.b32 	%r295, %r294, %r264, %r312;
	mov.b64 	%rd688, {%r295, %r293};
	shr.u64 	%rd689, %rd688, 32;
	st.global.u32 	[%rd675+28], %rd689;
	st.global.u32 	[%rd675+24], %rd688;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r296, %temp}, %rd742;
	}
	prmt.b32 	%r297, %r296, %r264, %r312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r298}, %rd742;
	}
	prmt.b32 	%r299, %r298, %r264, %r312;
	mov.b64 	%rd690, {%r299, %r297};
	shr.u64 	%rd691, %rd690, 32;
	st.global.u32 	[%rd675+20], %rd691;
	st.global.u32 	[%rd675+16], %rd690;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r300, %temp}, %rd747;
	}
	prmt.b32 	%r301, %r300, %r264, %r312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r302}, %rd747;
	}
	prmt.b32 	%r303, %r302, %r264, %r312;
	mov.b64 	%rd692, {%r303, %r301};
	shr.u64 	%rd693, %rd692, 32;
	st.global.u32 	[%rd675+12], %rd693;
	st.global.u32 	[%rd675+8], %rd692;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r304, %temp}, %rd728;
	}
	prmt.b32 	%r305, %r304, %r264, %r312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r306}, %rd728;
	}
	prmt.b32 	%r307, %r306, %r264, %r312;
	mov.b64 	%rd694, {%r307, %r305};
	shr.u64 	%rd695, %rd694, 32;
	st.global.u32 	[%rd675+4], %rd695;
	st.global.u32 	[%rd675], %rd694;
	mad.lo.s32 	%r316, %r313, %r35, %r316;
	setp.lt.s32	%p17, %r316, %r48;
	@%p17 bra 	BB0_2;

BB0_28:
	ret;
}


